{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install biopython"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oErepwJ-qou-",
        "outputId": "5844fbaf-3445-419c-ee8a-84e68363fe61"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: biopython in /usr/local/lib/python3.10/dist-packages (1.84)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from biopython) (1.26.4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 373
        },
        "id": "H2AJcofSp_i_",
        "outputId": "ff295b84-a079-4c64-e65e-4e7a472801c4"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-13-1a1cbb3acf44>\u001b[0m in \u001b[0;36m<cell line: 141>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    139\u001b[0m \u001b[0;31m# nj = NeighborJoining(dist_matrix, grouped_labels)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m \u001b[0mnj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNeighborJoining\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mEuc_distance_mat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrouped_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 141\u001b[0;31m \u001b[0mphylogenetic_tree\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild_tree\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    142\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Phylogenetic Tree (Newick Format):\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mphylogenetic_tree\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-13-1a1cbb3acf44>\u001b[0m in \u001b[0;36mbuild_tree\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    126\u001b[0m         \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 128\u001b[0;31m             \u001b[0mq_matrix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_q_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    129\u001b[0m             \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind_min_q\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mq_matrix\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m             \u001b[0mnew_label\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf\"({labels[i]},{labels[j]})\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-13-1a1cbb3acf44>\u001b[0m in \u001b[0;36mcompute_q_matrix\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    103\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 105\u001b[0;31m                 \u001b[0mq_matrix\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdist_matrix\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdist_matrix\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdist_matrix\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    106\u001b[0m                 \u001b[0mq_matrix\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mq_matrix\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mq_matrix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36msum\u001b[0;34m(a, axis, dtype, out, keepdims, initial, where)\u001b[0m\n\u001b[1;32m   2311\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2312\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2313\u001b[0;31m     return _wrapreduction(a, np.add, 'sum', axis, dtype, out, keepdims=keepdims,\n\u001b[0m\u001b[1;32m   2314\u001b[0m                           initial=initial, where=where)\n\u001b[1;32m   2315\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "import json\n",
        "import numpy as np\n",
        "from sklearn.cluster import AgglomerativeClustering\n",
        "from sklearn.metrics import silhouette_score\n",
        "import matplotlib.pyplot as plt\n",
        "from Bio import Phylo\n",
        "from io import StringIO\n",
        "import seaborn as sns\n",
        "\n",
        "file_path = '/content/clusters_dataset.json'\n",
        "with open(file_path, 'r') as f:\n",
        "    data = json.load(f)\n",
        "\n",
        "embeddings_file_path = '/content/clusters_dataset_embeddings.json'\n",
        "with open(embeddings_file_path, 'r') as f:\n",
        "    emb_data = json.load(f)\n",
        "\n",
        "def extract_strings_with_labels(nested_structure, parent_key=\"\"):\n",
        "    strings = []\n",
        "    if isinstance(nested_structure, dict):\n",
        "        for key, value in nested_structure.items():\n",
        "            new_key = f\"{parent_key}/{key}\" if parent_key else key\n",
        "            strings.extend(extract_strings_with_labels(value, new_key))\n",
        "    elif isinstance(nested_structure, list):\n",
        "        for item in nested_structure:\n",
        "            strings.append((item, parent_key))\n",
        "    return strings\n",
        "\n",
        "strings_with_labels = extract_strings_with_labels(data)\n",
        "# strings = [s[0] for s in strings_with_labels]\n",
        "labels = [s[1] for s in strings_with_labels]\n",
        "\n",
        "emb_result = np.array(extract_strings_with_labels(emb_data), dtype=\"object\")\n",
        "sentence = []\n",
        "weight = []\n",
        "label = []\n",
        "for entry in emb_result:\n",
        "    sentence.append(entry[0][0])\n",
        "    weight.append(entry[0][1])\n",
        "    label.append(entry[1])\n",
        "\n",
        "# Map topics to group numbers\n",
        "unique_topics = sorted(set(labels))\n",
        "topic_to_group = {topic: f\"Group {i + 1}\" for i, topic in enumerate(unique_topics)}\n",
        "grouped_labels = [topic_to_group[label] for label in labels]\n",
        "\n",
        "# Step 1: Compute the distance matrix using edit distance\n",
        "def edit_distance(s1, s2):\n",
        "    len_s1, len_s2 = len(s1), len(s2)\n",
        "    dp = np.zeros((len_s1 + 1, len_s2 + 1), dtype=int)\n",
        "\n",
        "    for i in range(len_s1 + 1):\n",
        "        dp[i][0] = i\n",
        "    for j in range(len_s2 + 1):\n",
        "        dp[0][j] = j\n",
        "\n",
        "    for i in range(1, len_s1 + 1):\n",
        "        for j in range(1, len_s2 + 1):\n",
        "            cost = 0 if s1[i - 1] == s2[j - 1] else 1\n",
        "            dp[i][j] = min(\n",
        "                dp[i - 1][j] + 1,       # Deletion\n",
        "                dp[i][j - 1] + 1,       # Insertion\n",
        "                dp[i - 1][j - 1] + cost # Substitution\n",
        "            )\n",
        "\n",
        "    return dp[len_s1][len_s2]\n",
        "\n",
        "def calculate_Euclidian(s1, s2):\n",
        "  len_s1, len_s2 = len(s1), len(s2)\n",
        "  Euc = np.zeros((len_s1, len_s2))\n",
        "  s1 = np.array(s1)\n",
        "  s2 = np.array(s2)\n",
        "  for i in range(len_s1):\n",
        "    for j in range(len_s2):\n",
        "      Euc[i][j] = np.sqrt(np.sum((s2[j] - s1[i]) ** 2))\n",
        "\n",
        "  return Euc\n",
        "\n",
        "\n",
        "# if len(strings) < 3:\n",
        "#     raise ValueError(\"Neighbor joining requires at least three strings in the dataset.\")\n",
        "\n",
        "# n = len(strings)\n",
        "# dist_matrix = np.zeros((n, n))\n",
        "# for i in range(n):\n",
        "#     for j in range(i + 1, n):\n",
        "#         dist = edit_distance(strings[i], strings[j])\n",
        "#         dist_matrix[i, j] = dist\n",
        "#         dist_matrix[j, i] = dist\n",
        "\n",
        "Euc_distance_mat = calculate_Euclidian(weight, weight)\n",
        "\n",
        "# Step 2: Implement Neighbor Joining Algorithm\n",
        "class NeighborJoining:\n",
        "    def __init__(self, dist_matrix, labels):\n",
        "        self.dist_matrix = dist_matrix\n",
        "        self.labels = labels\n",
        "        self.n = len(labels)\n",
        "\n",
        "    def compute_q_matrix(self):\n",
        "        n = self.n\n",
        "        q_matrix = np.full((n, n), np.inf)\n",
        "        for i in range(n):\n",
        "            for j in range(i + 1, n):\n",
        "                q_matrix[i, j] = (n - 2) * self.dist_matrix[i, j] - np.sum(self.dist_matrix[i, :]) - np.sum(self.dist_matrix[:, j])\n",
        "                q_matrix[j, i] = q_matrix[i, j]\n",
        "        return q_matrix\n",
        "\n",
        "    def find_min_q(self, q_matrix):\n",
        "        return np.unravel_index(np.argmin(q_matrix), q_matrix.shape)\n",
        "\n",
        "    def update_distance_matrix(self, i, j):\n",
        "        new_distances = []\n",
        "        for k in range(self.n):\n",
        "            if k != i and k != j:\n",
        "                new_dist = (self.dist_matrix[i, k] + self.dist_matrix[j, k] - self.dist_matrix[i, j]) / 2\n",
        "                new_distances.append(new_dist)\n",
        "        new_dist_matrix = np.delete(self.dist_matrix, [i, j], axis=0)\n",
        "        new_dist_matrix = np.delete(new_dist_matrix, [i, j], axis=1)\n",
        "        new_dist_matrix = np.vstack([new_dist_matrix, new_distances])\n",
        "        new_distances.append(0)\n",
        "        new_dist_matrix = np.hstack([new_dist_matrix, np.array(new_distances).reshape(-1, 1)])\n",
        "        return new_dist_matrix\n",
        "\n",
        "    def build_tree(self):\n",
        "        labels = self.labels[:]\n",
        "        while len(labels) > 2:\n",
        "            q_matrix = self.compute_q_matrix()\n",
        "            i, j = self.find_min_q(q_matrix)\n",
        "            new_label = f\"({labels[i]},{labels[j]})\"\n",
        "            labels.append(new_label)\n",
        "            self.dist_matrix = self.update_distance_matrix(i, j)\n",
        "            labels.pop(max(i, j))\n",
        "            labels.pop(min(i, j))\n",
        "            self.n -= 1\n",
        "        return f\"({labels[0]},{labels[1]})\"\n",
        "\n",
        "# Run Neighbor Joining\n",
        "# nj = NeighborJoining(dist_matrix, grouped_labels)\n",
        "nj = NeighborJoining(Euc_distance_mat, grouped_labels)\n",
        "phylogenetic_tree = nj.build_tree()\n",
        "print(\"Phylogenetic Tree (Newick Format):\", phylogenetic_tree)\n",
        "\n",
        "# Visualize the Tree using Bio.Phylo\n",
        "plt.figure(figsize=(15, 10))\n",
        "handle = StringIO(phylogenetic_tree)\n",
        "tree = Phylo.read(handle, \"newick\")\n",
        "Phylo.draw(tree, label_func=lambda x: x.name.split('/')[-1] if x.name else x.name)\n",
        "plt.show()\n",
        "\n",
        "# Grouped Heatmap\n",
        "sorted_indices = sorted(range(len(grouped_labels)), key=lambda i: grouped_labels[i])\n",
        "sorted_dist_matrix = Euc_distance_mat[np.ix_(sorted_indices, sorted_indices)]\n",
        "sorted_labels = [grouped_labels[i] for i in sorted_indices]\n",
        "\n",
        "plt.figure(figsize=(12, 10))\n",
        "sns.heatmap(\n",
        "    sorted_dist_matrix,\n",
        "    xticklabels=sorted_labels,\n",
        "    yticklabels=sorted_labels,\n",
        "    cmap=\"YlGnBu\",\n",
        "    annot=False\n",
        ")\n",
        "plt.title(\"Grouped Heatmap of Distance Matrix\")\n",
        "plt.xlabel(\"Sentences (Grouped by Topic)\")\n",
        "plt.ylabel(\"Sentences (Grouped by Topic)\")\n",
        "plt.show()\n",
        "\n",
        "# Step 3: Evaluate the Clustering\n",
        "clustering = AgglomerativeClustering(n_clusters=3, metric='precomputed', linkage='average')\n",
        "hclust_labels = clustering.fit_predict(Euc_distance_mat)\n",
        "\n",
        "# at least two distinct clusters\n",
        "if len(set(hclust_labels)) > 1:\n",
        "    # Compute silhouette score\n",
        "    sil_score = silhouette_score(Euc_distance_mat, hclust_labels, metric='precomputed')\n",
        "    print(\"Silhouette Score:\", sil_score)\n",
        "else:\n",
        "    print(\"Silhouette Score cannot be computed: Only one cluster detected.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "YDl8bHWFqGue"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}